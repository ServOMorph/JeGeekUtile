# Plaidoyer contre la surveillance automatisée des messages privés en Europe

## Nous, associations, collectifs de défense des libertés numériques et citoyens concernés,

Nous rappelons que la vie privée est un droit fondamental. Nous défendons **la confidentialité des communications** : personne n'est légitime à surveiller les échanges privés sans mandat judiciaire individuel.

Imposer une surveillance de masse constitue **une atteinte à l'intégrité des libertés démocratiques** et une négation des principes constitutionnels européens.

Nous considérons que le chiffrement des communications est une protection essentielle notamment face aux cybermenaces ; en résonance avec le principe à valeur constitutionnelle de présomption d'innocence, nous défendons l'idée que **la confiance renforce les bases d'une société démocratique**.

Nous défendons **l'égal accès aux communications sécurisées**, au droit de s'exprimer librement et sereinement, sans craindre une surveillance automatisée systématique fondée sur des technologies défaillantes.

Nous refusons toute politique de surveillance de masse fondée sur l'intelligence artificielle constituant **une forme de violence institutionnelle** : celle qui condamne des innocents par erreur algorithmique, réalise du tri automatisé entre les citoyens, multiplie les risques d'accusations injustifiées, produit de la défiance généralisée, et construit une société de contrôle permanent.

Pour nous, citoyens attachés aux libertés fondamentales, **nous refusons que les personnes aient à justifier leurs échanges privés** ; nous défendons des espaces dans la société où chacun peut communiquer librement sans surveillance préalable. Les conversations privées sont généralement intimes, elles concernent la vie personnelle, et par conséquent se partagent en fonction du consentement mutuel.

Nous nous opposons à la gestion sécuritaire fondée sur la surveillance préventive généralisée car elle est guidée par la peur et fondée sur l'idée de la communication privée comme une menace. Nous souhaitons rétablir **un débat démocratique éclairé**, sur la base de données fiables, et autour de valeurs communes, pour nous ressaisir du politique.

Pour cela, nous défendons une politique respectueuse de la dignité sans préjugés et sans peurs. Nous défendons **l'effectivité des droits pour tous et toutes** qui est un principe fondamental de l'État de droit.

Le principe de **vie privée** doit ainsi permettre l'accès à des communications confidentielles, à l'expression libre, à la sécurité numérique, à la protection contre les cybermenaces, sans qu'une surveillance de masse s'impose à tous. Penser une société démocratique revient à se sentir collectivement responsable face à la vulnérabilité numérique de chacun et donner une égale valeur à la protection des libertés de tous.

Nous défendons **le chiffrement des communications sans porte dérobée** pour garantir l'accès de tous et toutes à la confidentialité, sans qu'aucun système de surveillance automatisée ne s'applique de manière systématique et que la protection s'adresse à tous les citoyens sans discrimination.

Il est indispensable de **refuser les dispositifs de surveillance de masse** car il nous faut sortir de la logique sécuritaire fondée sur la peur en co-construisant des politiques pérennes de protection des libertés.

Il s'agit de penser la sécurité numérique dans le respect des droits fondamentaux, en reconnaissant la légitimité de la vie privée, qu'elle concerne les échanges quotidiens ou les communications sensibles ; **en reconnaissant le droit à la confidentialité comme fondamental**.

Nous défendons **l'égalité numérique** c'est-à-dire l'idée selon laquelle chaque personne, quel que soit son profil, a droit à la même protection de sa vie privée et participe à la vie démocratique sans surveillance préalable.

## DANS L'INTÉRÊT GÉNÉRAL, LES ÉTATS MEMBRES ONT UN RÔLE ESSENTIEL

Il s'agit pour eux de sortir du discours de la peur et de prendre leur part de **responsabilité dans la protection des droits fondamentaux**.

Plusieurs constats au niveau européen fragilisent la cohésion démocratique et obligent les États membres à refuser les dispositifs de surveillance de masse. D'un côté, les technologies d'intelligence artificielle présentent **un taux d'erreur de 24 à 35%** selon les benchmarks de 2025. De l'autre, ces systèmes génèrent des milliers de faux positifs quotidiens, condamnant des innocents et violant leur vie privée.

Les États membres se retrouvent face à une urgence démocratique provoquée par la dégradation des libertés fondamentales et ses répercussions concrètes sur les citoyens ; **il s'agit ici de refuser ces dispositifs et de protéger les droits de façon pérenne**.

Les États membres jouent un rôle-clé d'intermédiaire incontournable pour mettre en acte les normes internationales auxquelles l'Union Européenne est liée, **pour protéger et rendre effectifs les droits fondamentaux**.

Les États membres ont intérêt à refuser la surveillance de masse pour plusieurs raisons. Ils répondent tout d'abord à un besoin urgent de **préserver la cohésion démocratique** en protégeant la vie privée de tous et toutes, sans discrimination ; et plus loin, de préserver l'ensemble d'un écosystème démocratique, en garantissant les libertés sur leur territoire.

Le refus de la surveillance de masse est par ailleurs **une contribution au bien commun** permettant le maintien et le renforcement de la confiance des citoyens envers les institutions, de la vitalité démocratique et de la protection contre les dérives autoritaires.

Les États membres ont pour cela **des marges de manœuvre et des ressources juridiques** sur lesquelles s'appuyer pour refuser ces dispositifs.

Les moyens de chacun des États résultent également des potentialités à créer des alliances avec la société civile, les experts en sécurité numérique et les organisations de défense des droits humains.

## PROPOSITIONS D'ACTIONS : PROTÉGER LES LIBERTÉS NUMÉRIQUES

Imposer la surveillance des communications est une atteinte aux libertés fondamentales, c'est pourquoi au niveau européen et national, nous devons solliciter nos imaginaires et notre créativité : d'une part pour **interroger le cadre légal proposé**, identifier ses failles démocratiques, et dénoncer les violations des droits fondamentaux ; d'autre part, pour inventer des solutions alternatives, renforcer la protection numérique, et questionner nos priorités, pour protéger les libertés.

Nous proposons de **se saisir du droit comme ressource politique**.

### S'auto-saisir des compétences démocratiques pour assurer la protection des droits et refuser la surveillance de masse

#### Exiger un moratoire immédiat

Les États membres et le Parlement européen doivent **refuser tout dispositif de type Chat Control** ou surveillance automatisée des messages privés tant que les garanties suivantes ne sont pas assurées :

- **Audit indépendant des technologies** : évaluation publique du taux d'erreur, de fiabilité et des biais des systèmes d'IA proposés
- **Étude d'impact sur les droits fondamentaux** : analyse contradictoire avec participation de la société civile
- **Garantie de l'absence de porte dérobée** dans les systèmes de chiffrement
- **Protection contre les détournements autoritaires** : mécanismes juridiques contraignants

Ces temporalités doivent être pensées et mises en œuvre dans un lien de coopération entre les institutions européennes, les États membres et la société civile. Il est impératif d'organiser un **débat démocratique transparent**, dans des conditions mutuellement décidées.

Ces exigences prêtent attention au **collectif et à la démocratie**, en soutenant des formes de participation citoyenne, entre représentants politiques, experts indépendants, citoyens concernés, pour décider ensemble, s'inspirer mutuellement.

#### Le droit à la vie privée comme priorité pour garantir les autres libertés

Les États peuvent renforcer leur politique de protection des données et des communications avec plusieurs dispositifs :

- **Interdiction des portes dérobées** : garantie légale que le chiffrement de bout en bout reste inviolable
- **Contrôle parlementaire renforcé** sur tout dispositif de surveillance proposé
- **Transparence obligatoire** : publication des taux d'erreur, des faux positifs, des abus constatés
- **Recours juridiques effectifs** : droit de contester tout signalement automatisé avec accès au dossier complet
- **Sanctions dissuasives** contre les entreprises ou institutions violant la vie privée
- **Protection des lanceurs d'alerte** dénonçant les abus de surveillance

#### Assurer la fiabilité technologique avant tout déploiement

**Avant toute utilisation de l'IA dans un contexte de surveillance**, exiger :

- Taux d'erreur inférieur à 1% validé par audit indépendant
- Tests contradictoires avec participation d'experts en droits humains
- Transparence totale sur les algorithmes utilisés
- Possibilité de contestation humaine systématique
- Responsabilité juridique claire des concepteurs et déployeurs
- **Interdiction d'usage tant que ces critères ne sont pas remplis**

Les données actuelles montrent que **les IA génèrent 24 à 35% d'erreurs** selon les benchmarks de 2025. Ce taux est incompatible avec le respect des droits fondamentaux.

Tous ces garde-fous contribuent à **assurer la protection des citoyens**, et sortir de la logique de surveillance préventive, de suspicion généralisée et de violation des libertés, pour garantir la qualité de la démocratie.

### Protéger et soutenir le tissu associatif et citoyen

**Protéger les libertés associatives** pour les actions de défense des droits numériques et de protection de la vie privée.

**Soutenir et rendre visible le travail des organisations de défense des libertés** car protéger les droits c'est aussi informer : l'information sur les risques de surveillance, l'accompagnement vers des outils sécurisés nécessitent de la pédagogie, de l'écoute et de l'orientation vers les ressources existantes.

**Garantir la pérennité des actions de protection des libertés** en dehors des pressions politiques et lobbying industriel.

**Refuser les partenariats public-privé** qui placent les entreprises de surveillance en position de concevoir les politiques qui les concernent : sur la base d'une séparation claire entre intérêts commerciaux et protection des droits fondamentaux.

### Renforcer la démocratie numérique

**Instaurer des instances avec des fonctions :**

- De **contrôle démocratique** sur la légitimité des dispositifs de surveillance et le respect des droits
- De **critique indépendante** des propositions législatives afin de veiller au respect du principe de proportionnalité
- De **formuler des propositions alternatives**, avec par exemple des conseils consultatifs citoyens sur les politiques numériques

**Organiser des consultations publiques obligatoires** avant toute adoption de mesure touchant aux communications privées.

**Garantir la participation des experts indépendants** (techniques, juridiques, éthiques) dans toute évaluation des dispositifs proposés.

### Proposer des alternatives efficaces et respectueuses des droits

Au lieu de la surveillance de masse, **développer des approches ciblées et respectueuses des libertés** :

- Renforcement des moyens d'enquête judiciaire traditionnelle avec mandat individualisé
- Formation des forces de l'ordre aux techniques d'investigation numérique légales
- Coopération judiciaire internationale renforcée
- Investissement dans la prévention, l'éducation et l'accompagnement
- Protection des victimes renforcée sans surveillance généralisée
- Approche fondée sur les droits humains plutôt que sur la technologie

## Sources et références scientifiques

Les données citées dans ce plaidoyer sont issues de benchmarks et analyses publiés en 2025 :

**Sur les taux d'erreur de l'IA :**
- "Les hallucinations IA explosent en 2025 : qu'arrive-t-il à nos LLMs ?" — Lab-Sense, 14 septembre 2025
- "ChatGPT vous ment 48% du temps : la science révèle pourquoi les IA hallucinent" — Neper.ai, 2025
- "Les hallucinations des modèles LLM : enjeux et stratégies ETI 2025" — The Reveal Insight Project, 5 octobre 2025
- "OpenAI l'avoue : génération de contre-vérités, de citations fictives ou de biais" — Developpez.com, 14 septembre 2025
- Benchmark vidéo : "35% of AI Answers Are WRONG: HALLUCINATIONS"

**Taux d'erreur constatés :** 24% à 48% selon les modèles et contextes d'utilisation, avec une moyenne de 30 à 35% pour l'analyse de contenu complexe.

**Conclusion :** Surveiller les messages privés à l'aide d'IA présentant un taux d'erreur de près d'un tiers des cas traités crée un risque inacceptable d'accusations injustes, de violation massive de la vie privée et de perte de confiance démocratique. Les libertés fondamentales ne peuvent être sacrifiées sur l'autel d'une technologie défaillante.
